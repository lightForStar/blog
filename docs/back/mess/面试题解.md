# 基础

## java中基本类型和包装类型的区别

- 对于基本类型，在栈上分配空间，更加高效，包装类型是对象在堆上分配空间
- 包装类型存在缓存



## 为什么有了基本类型还需要包装类型

- Java是一门面向对象的语言，对于事物的描述应使用对象

- 基本类型没有类型转换功能，而包装类可以进行类型转换

- 表达含义更丰富假设我们要定义一个变量表示分数 如果用基本类型表示的话：int score;

  默认值为零，如果我想表示分数为空也就是没有参加考试就没法表现了因为值类型是无法赋空值的，如果使用包装类型Integer score,就可以表示这种情况，因为Integer的默认值为空。

- 有些地方不能直接用基本类型，比如集合



## 什么是hashcode，为什么重写equals方法时必须要重写hashcode

hashcode是对象的一个独有值，通常是将地址值转换为一个整数

重写原因：

1、HashMap中会通过equals方法和hashcode比较对象是否相等，如果不重写那么两个对象不会相等。

2、根据equals定义，两个对象相等，那么一定会有相等的hashcode。



## boolean类型占几个字节？

java规范中指出boolean类型占有几个字节依赖于虚拟机的实现

java虚拟机规范中指出boolean类型会转换为int类型处理，占用4个字节，boolean类型的数组每个boolean值占用一个字节

# 操作系统/JVM

## 进程

### 什么是进程

进程是程序的一次执行，是资源分配和系统调度的基本单位（概念）。进程的出现是为了提高系统的并发性，在古老的操作系统中只允许一道程序运行，如果遇到IO这种耗时操作，CPU就会被浪费。为了提高CPU的利用率，就需要在内存中保存多道程序，在CPU闲暇时切换运行，于是就出现了进程（进程是怎么出现的）。进程在操作系统的调度下会切换，这就是上下文切换。为了保证每个进程再次执行时能恢复到之前的状态，我们需要保存进程的信息。在操作系统中使用一个进程表保存所有的进程，并且使用一个数据结构保存每个进程的信息，这个数据结构就是PCB（process control block）。PCB中包含了进程ID、进程状态、程序计数器、堆栈指针、打开的文件等信息（进程的实现以及数据结构）。

### 什么是线程

线程也被称为轻量级进程，线程未出现之前，进程是操作系统调度的基本单位，有了线程之后，线程变成了操作系统执行的基本单位。在程序中经常会有这样的需求，一个程序中包含多个任务，多个任务需要同时进行，基于这个场景抽象出了线程的概念，这样让我们的程序设计更加简单。保存线程独有信息的结构是线程控制块（Thread Control Block，TCB）,TCB包含了程序计数器、寄存器、堆栈、状态等

### 进程和线程的区别

- 进程是资源分配的基本单位，线程是操作系统调度的基本单位
- 进程较为笨重，上下文切换时间要比线程长
- 进程间是独立的、隔离的，线程之间是会相互影响的（操作了共享资源）

### 进程和线程的联系

一个进程内通常包含了多个线程，多个线程共享进程的资源，映射到jvm中便是

线程共享进程的堆和方法区，每个线程都有自己的程序计数器、虚拟机栈、本地方法栈

![image-20201024105135979](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/20201024105136.png)

### 进程间的通信方式

- 管道（匿名管道）：用于父子进程间的通信
- 有名管道：解决匿名管道的局限性，任意进程之间均可通信，通过一个保存在磁盘的文件
- 信号：通过信号进行消息传递，例如在linux中的kil -9 pid，通知操作系统杀死pid进程
- 信号量：通过操作系统PV原语进行信号量（变量）的增减达到通信的目的
- 消息队列：进程间通过读取和存入消息到消息队列中进行通信，消息队列一般存放在内核中
- 远程过程调用（RPC）：适用于在不同的计算机进程之间进行通信，通过Socket传递消息

### 进程调度算法

- 先来先服务（批处理系统适用，非抢占式）
- 短作业优先（批处理系统适用，非抢占式）
- 时间片轮转（交互系统适用）
- 优先级调度（可能产生进程饥饿现象）
- 多级队列（优先级越高，运行的时间片数量越少，运行完移动到下一级队列）

## IO模型

首先需要了解的是在我们进行IO的时候是有两部分操作组成的，以读取文件为例，第一部分是线程到用户空间中读取数据，第二部分是操作系统把文件数据由内核空间读取到用户空间。Linux操作系统中一共有五种IO模型分别是：阻塞式IO、非阻塞式IO、信号驱动式IO、IO复用模型、异步IO

### 阻塞式IO

阻塞式IO对应的就是JAVA中的Socket，用户应用程序通过系统调用recvfrom获取数据，此时如果数据没有从内核转移到用户空间，那么用户的应用程序就会堵塞，直到数据准备好。

![](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/sd546.jpg)

### 非阻塞式IO

非阻塞式IO通过轮询检测内核数据是否已复制到用户空间，直到数据已经复制到用户空间，这时通过recvfrom系统调用从用户空间获取数据，在轮询的过程中应用程序可以进行其他的操作

![](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/dsad456.jpg)

### 信号驱动IO

非阻塞式IO需要应用程序一直轮询，这无疑增加了应用程序的cpu资源消耗，那么能不能有一种方式能够减少这种不必要的操作呢？答案是有，我们可以通过信号（事件）的方式让操作系统主动通知应用程序数据准备好了。

应用进程预先向内核注册一个信号处理函数，然后用户进程返回，并且不阻塞，当内核数据准备就绪时会发送一个信号给进程，用户进程便在信号处理函数中开始把数据拷贝的用户空间中。

![](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/45sda.jpg)



### IO复用模型

这种模型比信号驱动模型多了一个IO多路复用程序，通过这个程序统一管理应用程序访问内核，在Linux中对应select系统调用，多个进程的IO注册到select上，由select负责监听每一个进程的IO事件，如果被监听的进程IO数据都没有准备好，那么select系统调用会堵塞，当任意一个IO所需的数据准备好之后，select调用就会返回，然后进程在通过`recvfrom`来进行数据拷贝。

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/20201021174340)

**这里的IO复用模型，并没有向内核注册信号处理函数，所以，他并不是非阻塞的。**进程在发出`select`后，要等到`select`监听的所有IO操作中至少有一个需要的数据准备好，才会有返回，并且也需要再次发送请求去进行文件的拷贝。

## 内存管理

### 直接内存管理

进程直接操作内存的物理地址，这样无法同时运行两个进程，进程之间修改内存会相互冲突，进程A如果修改了进程B的程序，可能会导致进程B崩溃，更严重的是如果进程修改了操作系统的进程空间，操作系统可能会被破坏

### 地址空间（抽象存储层）

地址空间是进程可内存寻址的地址集合，每个进程都会有自己独立的地址空间，如何做到地址空间的独立呢？例如两个进程分配的内存都指定了28这个内存地址，那样不是冲突了吗？这个时候我们就需要进行地址重定位了。通常我们可以使用基址寄存器和界限寄存器进行地址重定位，将进程的起始地址放入基址寄存器，长度放入界限寄存器中，当内存增加时我们就需要动态分配内存了。

### 内存超载

启动太多进程，内存装不下了这就是内存超载，通常有两种技术解决，一是交换技术，将空闲的进程换出到磁盘，等需要调度时再换入（多次交换可能会导致内存碎片化）；二是虚拟内存技术，将进程的一部分程序调入内存，其他部分调度时换入内存

### 空闲内存管理

- 位图法
- 空闲区链表

# Redis

## 什么是Redis

Redis 是 C 语言开发的一个开源的、高性能的内存数据库，可以用作数据库、缓存、消息中间件等。它是一种 NoSQL（not-only sql，泛指非关系型数据库）的数据库（简述）。Redis 作为一个内存数据库：（优点）

- 性能优秀，数据在内存中，读写速度非常快。
- 单进程单线程，是线程安全的，采用 IO 多路复用机制。
- 丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等。
- 支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载。
- 可以用作分布式锁。
- 可以作为消息中间件使用，支持发布订阅。



## Redis的数据类型

### Redis中如何描述数据类型

![](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/40.jpg)

Redis中使用redisObject 描述所有的数据类型，redisObject 最主要的信息如上图所示：type 表示一个 value 对象具体是何种数据类型，encoding 是不同数据类型在 Redis 内部的存储方式。比如：type=string 表示 value 存储的是一个普通字符串，那么 encoding 可以是 raw 或者 int。

### Redis中5种类型的编码

![image-20201009104357476](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/image-20201009104357476.png)

### string

**介绍：**string 是 redis 最基本的类型，一个 key 对应一个 value。value 不仅是 string，也可以是数字。string 类型是二进制安全的，意思是 redis 的 string 类型可以包含任何数据，比如 jpg 图片或者序列化的对象。string 类型的值最大能存储 512M。

**常用命令:** set,get,decr,incr,mget 等。

**应用场景** ：常规 key-value 缓存应用；常规计数：微博数，粉丝数等。

### hash

**介绍** ：Hash 是一个键值（key-value）的集合。redis 的 hash 是一个 string 的 key 和 value 的映射表，Hash 特别适合存储对象。

**常用命令** ：hget,hset,hgetall 等。

**应用场景** ：hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如我们可以 hash 数据结构来存储用户信息，商品信息等等。

### list

**介绍** ：list 列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部（左边）或者尾部（右边） ：

**常用命令：**lpush、rpush、lpop、rpop、lrange(获取列表片段)等。

**应用场景** ：list 应用场景非常多，也是 Redis 最重要的数据结构之一，比如 twitter 的关注列表，粉丝列表都可以用 list 结构来实现。

### set

**介绍** ：set 是 string 类型的无序集合。集合是通过 hashtable 实现的。set 中的元素是没有顺序的，而且是没有重复的。

**常用命令：** sdd、spop、smembers、sunion 等。

**应用场景** ：redis set 对外提供的功能和 list 一样是一个列表，特殊之处在于 set 是自动去重的，而且 set 提供了判断某个成员是否在一个 set 集合中。

### zset

**介绍** ：zset 和 set 一样是 string 类型元素的集合，且不允许重复的元素。

**常用命令：** zadd、zrange、zrem、zcard 等。

**使用场景：**sorted set 可以通过用户额外提供一个优先级（score）的参数来为成员排序，并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择 sorted set 结构。和 set 相比，sorted set 关联了一个 double 类型权重的参数 score，使得集合中的元素能够按照 score 进行有序排列，redis 正是通过分数来为集合中的成员进行从小到大的排序。

**Redis 数据类型应用场景总结:**

![image-20201009135608898](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/image-20201009135608898.png)

## Redis中的缓存一致性问题

分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是**强一致性**的，那么就**不要使用缓存**。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括合适的缓存更新策略，**更新数据库后及时更新缓存、缓存失败时增加重试机制。**

## Redis 缓存雪崩

同一时间内缓存大面积失效，导致请求都落在数据库，数据库会被打崩。

解决方案：

1、在批量往 Redis 存数据的时候，把每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。

2、设置热点数据永不过期

## Redis 缓存穿透

缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求，举个栗子：我们数据库的 id 都是从 1 自增的，如果发起 id=-1 的数据或者 id 特别大不存在的数据，这样的不断攻击导致数据库压力很大，严重会击垮数据库。

解决方案：

1、在接口层增加校验，比如用户鉴权，参数做校验，不合法的校验直接 return，比如 id 做基础校验，id<=0 直接拦截。

2、使用布隆过滤器，布隆过滤器是一个非常大的位数组，使用多个hash函数对存入的key进行哈希操作映射到多个位置，如果该key不存在那么映射后的数组位置的值为初始值，否则为特定值，有一定的误判率，不同的key可能会哈希到同样的位置导致某个元素不存在但是误判为存在。

## Redis缓存击穿

缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。

解决方案：

1、设置热点数据永不过期

2、加上互斥锁

## Redis为什么是单线程的

因为 Redis 完全是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章的采用单线程的方案了

## Redis 是单线程的，为什么还能这么快

- Redis 完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度是 O(1)。
- 数据结构简单，对数据操作也简单。
- 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的 CPU 切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。
- 使用多路复用 IO 模型，非阻塞 IO。



## Redis 和 Memcached 的区别

1. **存储方式上** ：memcache 会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis 有部分数据存在硬盘上，这样能保证数据的持久性。
2. **数据支持类型上** ：memcache 对数据类型的支持简单，只支持简单的 key-value，，而 redis 支持五种数据类型。
3. **value 的大小** ：redis 可以达到 1GB，而 memcache 只有 1MB。

## Redis的淘汰策略

![image-20201009145937806](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/image-20201009145937806.png)

## redis 持久化机制

redis 为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。Redis 的持久化策略有两种：RDB、AOF，Redis 默认是快照 RDB 的持久化方式。

### RDB

**介绍**

快照形式是直接把内存中的数据保存到一个 dump 的文件中，定时保存，保存策略。

**快照触发条件**

RDB生成快照可自动促发，也可以使用命令手动触发，以下是redis触发执行快照条件

1. 客户端执行命令save和bgsave会生成快照；
2. 根据配置文件save m n规则进行自动快照；
3. 主从复制时，从库全量复制同步主库数据，此时主库会执行bgsave命令进行快照；
4. 客户端执行数据库清空命令FLUSHALL时候，触发快照；
5. 客户端执行shutdown关闭redis时，触发快照；

**save命令触发**

客户端执行save命令，该命令强制redis执行快照，这时候redis处于阻塞状态，不会响应任何其他客户端发来的请求，直到RDB快照文件执行完毕，所以请慎用。

**bgsave命令触发**

bgsave命令可以理解为background save即：“后台保存”。当执行bgsave命令时，redis会fork出一个子进程来执行快照生成操作，需要注意的redis是在fork子进程这个简短的时间redis是阻塞的（此段时间不会响应客户端请求，），当子进程创建完成以后redis响应客户端请求。其实redis自动快照也是使用bgsave来完成的。

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/1075473-20180725172641202-1573986143.png)

**save m n规则触发** 

save m n规则说明：在指定的m秒内，redis中有n个键发生改变，则自动触发bgsave。该规则默认也在redis.conf中进行了配置，并且可组合使用，满足其中一个规则，则触发bgsave，以save 900 1为例，表明当900秒内至少有一个键发生改变时候，redis触发bgsave操作。

**优点：**

1. RDB 是一个非常紧凑（compact）的文件，体积小，因此在传输速度上比较快，因此适合灾难恢复。 
2. RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 `fork` 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。
3. RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

**缺点：**

1. RDB是一个快照过程，无法完整的保存所以数据，尤其在数据量比较大时候，一旦出现故障丢失的数据将更多。
2. 当redis中数据集比较大时候，RDB由于RDB方式需要对数据进行完成拷贝并生成快照文件，fork的子进程会耗CPU，并且数据越大，RDB快照生成会越耗时。
3. RDB文件是特定的格式，阅读性差，由于格式固定，可能存在不兼容情况。

### AOF

AOF可以将Redis执行的**每一条写命令追加到磁盘文件(appendonly.aof)中**,在redis启动时候优先选择从AOF文件恢复数据。由于每一次的写操作，redis都会记录到文件中，所以开启AOF持久化会对性能有一定的影响。

redis提供了三种**同步策略**同步命令到硬盘

```properties
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘,默认设置
appendfsync no        #让操作系统决定何时进行同步
```

**AOF重写**：当开启的AOF时，随着时间推移，AOF文件会越来越大,当然redis也对AOF文件进行了优化，即触发AOF文件重写条件（后续会说明）时候，redis将使用bgrewriteaof对AOF文件进行重写。这样的好处在于减少AOF文件大小，同时有利于数据的恢复。

**重写触发条件** 

手动触发：客户端执行bgrewriteaof命令。

自动触发：自动触发通过以下两个配置协作生效：

- auto-aof-rewrite-min-size: AOF文件最小重写大小，只有当AOF文件大小大于该值时候才可能重写,4.0默认配置64mb。
- auto-aof-rewrite-percentage：当前AOF文件大小和最后一次重写后的大小之间的比率等于或者等于指定的增长百分比，如100代表当前AOF文件是上次重写的两倍时候才重写。　

**重写过程**

​	![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/1075473-20180726171841786-525684493.png)

**优点：**

1. 数据更完整，秒级数据丢失(取决于设置fsync策略)。
2. 兼容性较高，由于是基于redis通讯协议而形成的命令追加方式，无论何种版本的redis都兼容，再者aof文件是明文的，可阅读性较好。

**缺点：**

1. 数据文件体积较大,即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大。
2. 相对RDB方式，AOF速度慢于RDB，并且在数据量大时候，恢复速度AOF速度也是慢于RDB。
3. 由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但是对于我们来说是可以接受的。

### RDB-AOF混合持久化

**混合持久化**就是同时结合RDB持久化以及AOF持久化混合写入AOF文件。这样做的好处是可以结合 rdb 和 aof 的优点, 快速加载同时避免丢失过多的数据，缺点是 aof 里面的 rdb 部分就是压缩格式不再是 aof 格式，可读性差。

4.0版本的**混合持久化默认关闭**的，通过aof-use-rdb-preamble配置参数控制，yes则表示开启，no表示禁用，默认是禁用的，可通过config set修改。

**混合持久化过程**

混合持久化同样也是通过bgrewriteaof完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据，如下图：

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/1075473-20180726181756270-1907770368.png)

**优点：**

1. 混合持久化结合了RDB持久化 和 AOF 持久化的优点, 由于绝大部分都是RDB格式，加载速度快，同时结合AOF，增量的数据以AOF方式保存了，数据更少的丢失。

**缺点：**

1. 兼容性差，一旦开启了混合持久化，在4.0之前版本都不识别该aof文件，同时由于前部分是RDB格式，阅读性较差

   
   
   

# MySQL

## 什么是MySQL

MySQL 是一个关系型数据库，使用 SQL 语言进行增删改查操作，目前属于 Oracle 旗下的产品。

MySQL 数据库开源免费，能够跨平台，支持分布式，性能也不错，可以和 PHP、Java 等 Web 开发语言完美配合，非常适合中小型企业作为 Web 数据库（网站数据库）。

## 索引

### 按节点数据存储方式分

#### 聚簇索引（主键索引）

每一个索引节点存放的是该条记录全部数据

#### 非聚簇索引（二级索引）

每一个索引节点存放的是主键

### 按索引的数据结构划分

#### 哈希表

索引底层数据结构为哈希表，对于单条记录的查询时间非常快

缺点：不支持范围查询

#### B+树

索引底层数据结构为B+树，叶子节点存储所有数据，并且叶子节点之间以指针的形式相连，能快速进行范围查找

### B+树索引如何加快查找速度

#### MySQL存储基本结构--页

![MySQL的基本存储结构是页](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/28559421.jpg)

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/82053134.jpg)

- **各个数据页可以组成一个双向链表**
- 每个数据页中的记录又可以组成一个单向链表
  - 每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录
  - 以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。

所以说，如果我们写select * from user where indexname = 'xxx'这样没有进行任何优化的sql语句，默认会这样做：

1. **定位到记录所在的页：需要遍历双向链表，找到所在的页**
2. **从所在的页内中查找相应的记录：由于不是根据主键查询，只能遍历所在页的单链表了**

很明显，在数据量很大的情况下这样查找会很慢！这样的时间复杂度为O（n）。

#### 使用B+树索引

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/5373082.jpg)

很明显的是：没有用索引我们是需要遍历双向链表来定位对应的页，现在通过 **“目录”** 就可以很快地定位到对应的页上了！（二分查找，时间复杂度近似为O(logn)）

其实底层结构就是B+树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录。

### 覆盖索引

在二级索引中，如果索引本身不能提供查询的数据，需要进行回表操作到主键索引查询，如果索引本身能提供查询的数据则不需要进行回表，这种索引称为覆盖索引。

eg:创建了索引(username,age),在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表。

```sql
select username , age from user where username = 'Java' and age = 22
```

### 索引下推

**索引下推**（index condition pushdown ）简称ICP，在**Mysql5.6**的版本上推出，用于优化查询。使用索引下推后，如果判断条件中包含索引字段会直接筛选，不符合条件的不进行回表操作

eg:创建了索引(username,age)，表中有**username，age，address**三个属性

```sql
select username , age，address from user where username like 'Java%' and age = 22
```

假设有两条数据

| username  | age  |
| --------- | ---- |
| JavaScrip | 25   |
| JavaApp   | 22   |

**未使用索引下推前**，通过索引(username,age)找到username符合Java%，回表操作进行age判断，此时会找到两条数据，然后回表两次，根据age筛选出JavaApp这条数据

**使用索引下推后**，通过索引(username,age)找到username符合Java%，同时筛选age得到一条记录JavaApp，回表一次获得数据

## InnoDB和MyISAM比较

- InnoDB支持事务，MyISAM不支持
- InnoDB支持行锁和表锁、MyISAM只支持表锁
- InnoDB具备crash-safe（灾难恢复）能力,MyISAM不支持
- InnoDB支持聚簇索引，MyISAM支持非聚簇索引
- InnoDB支持外键，MyISAM不支持

## 事务

### 什么是事务

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。

### 四大特性ACID

- 原子性（Atomicity）
```txt
原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。
```
- 一致性（Consistency）
```txt
事务的执行使数据从一个状态转换为另一个状态，但是对于整个数据的完整性保持稳定。
```
- 隔离性（Isolation）
```txt
隔离性是当多个用户并发访问数据库时，比如同时操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
```
- 持久性（Durability）
```txt
当事务正确完成后，它对于数据的改变是永久性的。
```

### 隔离级别

- 读未提交（read uncommitted）
```
读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
```
- 读已提交（read committed）
```
读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
```
- 可重复读（repeatable read）
```
可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
```
- 串行化（serializable ）
```
串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
```

```
读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。
可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。
串行：我的事务尚未提交，别人就别想改数据。
这4种隔离级别，并行性能依次降低，安全性依次提高。
```

#### 实现原理

通过undo.log实现，对于一条记录每一个事务的更新都会记录事务号，更新的量（以便恢复到该事务版本的read-view）。

在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。

![img](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/85WdGq.png)

**查询这条记录的时候，不同时刻启动的事务会有不同的read-view,假如你开启的事务更改了read-view视图里面的值，也不会对其他事务造成影响**

#### 隔离级别解决了哪些问题

数据读取产生的问题：

- 脏读
```
事务中的修改,即使没有提交,对其它事务也是可见的. 
如：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
```
- 不可重复读
```
A事务查看，B事务修改提交，A事务再次查看，数据不一样。
```
- 幻读
```
幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。
更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。
```
- 幻读的例子

| 会话A                                         | 会话B                                        | 步骤说明                                 |
| --------------------------------------------- | -------------------------------------------- | ---------------------------------------- |
| begin                                         | begin                                        | 开启事务                                 |
| select * form user;                           | ~                                            | 会话A查询得到第一次结果                  |
| ~                                             | insert into user(id,name) values(4,"lisi0"); | 会话B插入一条数据                        |
| ~                                             | commit;                                      | 会话B提交事务                            |
| select * form user;                           | select * form user;                          | 会话A第二次查询结果，会话B第一次查询结果 |
| insert into user(id,name) values(4,"wangwu"); | ~                                            | 会话A插入id（主键）为4的记录             |

**结果说明**
- 会话A第一次查询得到的结果

![image](https://s1.ax1x.com/2020/03/22/85vT3T.png)
- 会话A第二次查询得到的结果

![image](https://s1.ax1x.com/2020/03/22/85vT3T.png)
- 会话B第一次查询得到的结果

![image](https://s1.ax1x.com/2020/03/22/85zgTs.png)

- 会话A插入id为4的记录得到的结果

![image](https://s1.ax1x.com/2020/03/22/85xhse.png)

**幻读的小总结**

1. 幻读并非什么读取两次返回结果集不同，而是事务在插入事先检测不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测读获取到的数据如同鬼影一般。
2. 不可重复读侧重表达 读-读不一致，幻读则是说 读-写不一致，用写来证实读的是鬼影

#### 隔离级别对应解决的问题

```
读未提交（read uncommitted）会产生上面的三个问题；
读提交（read committed）解决了脏读问题，存在不可重复读，幻读； 
可重复读（repeatable read）解决了不可重复读问题，存在幻读；
串行化（serializable ）解决了所有问题，但是严重影响效率
```

### MVCC

![image-20201019164910344](https://lightforstar.oss-cn-shenzhen.aliyuncs.com/blog/image-20201019164910344.png)

### 锁



## MySQL优化

有两种类型

- SQL语句优化
- 大数据表的优化

### SQL语句优化

**查询**

对于查询而言优化一般针对的是慢查询的SQL，我们可以开启MySQL的慢查询日志，通过慢查询日志找到执行速度慢的SQL

慢查询亦可分为两类

- 偶发性执行慢

​        偶发性执行慢可能有两个原因，1、MySQL在刷新脏页，将脏页中的数据落盘（redo log 写满了需要同步到磁盘） 2、没抢到锁堵塞

- 经常性执行慢

​       一般是SQL语句书写有问题

**人为使用索引错误**

​	1、未建立索引

​	2、查询时对索引使用了函数

​	3、查询时对索引列进行运算

​	4、使用联合索引时不符合最左前缀匹配原则

​	5、查询时索引列有隐式类型转换

**MySQL选择索引错误**

​	MySQL通过优化器选择索引，由于走索引可能会导致回表操作，需要二次查询才能得到结果，如果全表扫描快执行器就会考虑走全表扫描，那么MySQL判断的标准是什么呢？MySQL是根据索引的区分度进行判断的，区分度指的是数据的异同形，如果索引的数据每一个都是不重复的那么区分度就非常高，走索引的优势就越大，MySQL判断区分度的方法是抽样调查，选取部分数据计算区分度，这就会有一定的误判几率。我们可以通过force index(index_name)强制走索引

```sql
select * from t force index(a) where c > 100 and c < 100000;
```

### 大数据表的优化

MySQL中一张表的数据不宜超过一千万条记录，超过之后查询速度会大幅度下降

#### 拆分

针对大表，我们可以进行拆分，根据拆分的维度不一样又可以分为水平拆分和垂直拆分

- **水平拆分**

 将数据拆分到多个表中，每个表存放一部分数据

**水平拆分的优点：** 可以承载非常大的数据量

**水平拆分的缺点：** 跨节点的分布式事务难以解决，跨节点的join操作性能差

**数据库分片的两种常见方案：**

1、**客户端代理：** **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。

2、**中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。

- **垂直拆分**

将表按照字段进行拆分，每个表存放一部分的字段

**垂直拆分的优点：** 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

**垂直拆分的缺点：** 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

#### 读写分离

经典的数据库拆分方案，主库负责写，从库负责读；

